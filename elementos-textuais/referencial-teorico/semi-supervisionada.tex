\subsection{Aprendizagem Semi-Supervisionada}
\label{subsec:semi-supervised-learning}
Esta categoria como o próprio nome sugere é uma mistura entre aprendizagem supervisionada e não-supervisionada, 
esta mistura se dá por utilizar tanto exemplos rotulados como exemplos não rotulados para treino, na maiorias dos casos se utiliza 
mais dados não rotulados do que rotulados, isto porque é mais barato e mais fácil de adquiri-los. É útil quando o processo de preparação
dos dados é muito custoso para realizar treino com exemplos  rotulados.
Alguns dos exemplos que utilizam este tipo e aprendizagem é reconhecimento de fala e de rostos, justamente pela variedade
de formas de rostos, dicção ou sotaques diferentes.

Dado que temos \textit{L} e \textit{U} sendo a quantidade exemplos rotulados e sem rótulos, temos $X_{1:L}$ e $X_{L+1: L+U}$ como vetores de atributos dos exemplos
rotulados e não rotulados respectivamente e o rótulo $y_{1:L}$.  O objetivo de um algoritmo semi-supervisionado é definir 
um classificador $f : x \rightarrow y$ com base em exemplos rotulados e não-rotulados. Existem dois paradigmas que a aprendizagem
semi-supervisionado utiliza, são eles:

\begin{alineas}
	\item \textbf{Aprendizagem Transdutiva\footnote{Transdutivo é a ligação de fatos que não mantêm relação entre si.}}, tem como objetivo aplicar o classificador $f$ somente em exemplos 
	não-rotulados durante o treinamento, e este classificador não generaliza exemplos desconhecidos.\cite{Zhu03semi-supervisedlearning,Zhou04learningwith}
	\item \textbf{Aprendizagem Indutiva}, tem como objetivo identificar um classificador $f$, que pode ser aplicado em exemplos desconhecidos.
	\cite{indutive-learning} 
\end{alineas} 